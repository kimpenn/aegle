# Top-level configuration for CODEX pipeline
exp_id: D16_img0034_1
sample_id: 16-56

# -----------------------------------------------------------------------------
# (A) Data Source and Basic Image Settings
# -----------------------------------------------------------------------------
data:
  # Path to the main .qptiff or .tiff file for the CODEX image
  file_name: 
    /workspaces/codex-analysis/data/uterus/D16/img0034/processed_hubmap/img0034_manual_16-56_Uterus_Endocervix_Scan1.ome.tiff

  # Path to the TSV file containing antibody definitions (one row per channel)
  antibodies_file: 
    /workspaces/codex-analysis/data/uterus/D11/img0018/extras/antibodies.tsv

  # Microns per pixel for this image; used in downstream calculations (e.g., segmentation scaling)
  image_mpp: 0.5

  # Whether to compute and save channel-level statistics (min, max, 95th percentile, etc.)
  generate_channel_stats: false

# -----------------------------------------------------------------------------
# (B) Channel Configuration
# -----------------------------------------------------------------------------
channels:
  # Name of the nuclear marker channel (must match an entry in the antibodies file)
  nuclear_channel: DAPI

  # Name(s) of the whole-cell marker channel(s). If multiple, they will be merged.
  wholecell_channel:
    - CD44
    - SMA
    - CD34
    - CD31
    - DNALI1
patching:
  # Split mode can be "full_image", "halves", "quarters", or "patches"
  split_mode: full_image

  # Split direction can be "vertical" or "horizontal"
  split_direction: NULL

  # Size (height, width) of each patch (in pixels)
  patch_height: NULL
  patch_width: NULL

  # Overlap fraction between adjacent patches (0.1 means 10% overlap)
  overlap: NULL

# -----------------------------------------------------------------------------
# (D) Visualization Settings
# -----------------------------------------------------------------------------
visualization:
  # Whether to save RGB visualizations of all patches
  visualize_patches: true

  # Whether to keep a temporary compressed cache of the full multi-channel patches for reuse
  cache_all_channel_patches: true

  # Whether to save the raw multi-channel patches to disk at the end of the run
  save_all_channel_patches: false

  # Number of threads to use when compressing all-channel patches (0=auto, -1=all cores)
  all_channel_compression_threads: 120

  # Whether to visualize and save the segmentation mask overlay (after segmentation)
  visualize_segmentation: true

# -----------------------------------------------------------------------------
# (E) QC (Patch-Level Quality Control)
# -----------------------------------------------------------------------------
patch_qc:
  # Minimum fraction of non-zero pixels required for a patch to be considered valid
  non_zero_perc_threshold: 0.05

  # Minimum mean intensity for the patch to be considered informative
  mean_intensity_threshold: 1.0

  # Minimum standard deviation required to avoid marking patches as too "flat"
  std_intensity_threshold: 1.0

# -----------------------------------------------------------------------------
# (F) Segmentation Parameters and Output Options
# -----------------------------------------------------------------------------
segmentation:
  # Path to the segmentation model directory (e.g., for DeepCell or another tool)
  model_path: /workspaces/codex-analysis/data/deepcell/v7/MultiplexSegmentation

  # If True, save segmentation masks as images
  save_segmentation_images: true

  # If True, pickle the entire codex_patches object (containing segmentation results, etc.)
  save_segmentation_pickle: true
  segmentation_pickle_compression: zstd      # options: none|gzip|bz2|lzma|zstd
  segmentation_pickle_compression_level: 5   # optional, honours backend limits
  segmentation_pickle_compression_threads: 0   # 0=auto, -1=all cores
  # If True, run segmentation analysis
  # Calculate metrics based on the segmentation results to describe the data quality
  segmentation_analysis: false
  density_analysis:
    calculate_global_density: false
    calculate_local_density: false

  # Mask repair configuration (cell-nucleus matching and repair)
  repair:
    # Enable GPU acceleration for mask repair operations (Phase 3 with vectorized matching)
    # Phase 3 provides 10-20x speedup for mismatch computation and matching on large samples
    # - GPU morphology: 10-50x speedup for boundary detection
    # - GPU overlap: 3-6x speedup for overlap matrix computation (Phase 4)
    # - GPU overlap bincount: 400-540x speedup (Phase 5c, recommended for >100K cells)
    # - GPU mismatch (Phase 3): 100-1000x speedup via vectorized boolean operations
    # Requires CuPy and CUDA-compatible GPU. Falls back to CPU if GPU unavailable.
    use_gpu: true

    # Phase 5c: Use bincount approach for overlap computation (400-540x speedup)
    # When True: tries bincount first, falls back to Phase 4 if needed
    # When False: uses Phase 4 sequential approach (baseline)
    # Recommended: True for samples with >100K cells
    # Phase 5c benefits: 54 min → 6-8 sec on D18_0 (1.99M cells)
    use_bincount_overlap: true

    # Batch size for GPU overlap computation (null = auto-size based on GPU memory)
    # Manual override useful for GPU memory constrained environments
    # Auto-sizing estimates based on mask dimensions and available VRAM
    # Only used for Phase 4 fallback (Phase 5c auto-manages memory)
    gpu_batch_size: NULL

    # Batch size for GPU mismatch computation (null = auto-size, 10000 = default)
    # Phase 3 feature: controls how many cell-nucleus pairs to process per GPU batch
    # Larger batches = faster but more GPU memory. Typical: 5K-50K pairs per batch.
    gpu_mismatch_batch_size: NULL

    # Number of GPUs to use for overlap computation (Stage 3)
    # Set to 2 to distribute work across 2 GPUs in parallel (~2x speedup)
    # - Phase 5c: distributes chunks across GPUs
    # - Phase 4: distributes cells across GPUs (cell-level round-robin)
    # Requires multiple CUDA-compatible GPUs. Falls back to single GPU if unavailable.
    overlap_num_gpus: 2

    # Number of GPUs to use for mismatch computation (Stage 4)
    # Set to 2 to distribute batches across 2 GPUs in parallel (1.87x speedup)
    # Saves ~12 min per sample on large datasets (>150K overlapping pairs)
    # Requires multiple CUDA-compatible GPUs. Falls back to single GPU if unavailable.
    mismatch_num_gpus: 2

    # Automatically fallback to CPU if GPU errors occur
    # Recommended to keep enabled for robustness
    # Fallback chain: Phase 5c → Phase 4 → CPU
    fallback_to_cpu: true

    # Log detailed GPU performance metrics (timing, speedup, memory usage)
    # Useful for performance analysis and optimization
    log_gpu_performance: true


# -----------------------------------------------------------------------------
# (G) Testing Data Disruption (Optional) 
#     If you do not want to disrupt your data, set "type" to null or remove this block.
# -----------------------------------------------------------------------------
testing:
  data_disruption:
    # Disruption type can be "downsampling" or "gaussian"
    type: NULL

    # Intensity level of disruption (1-5, for instance)
    level: NULL

    # Whether to save the disrupted patches to disk (for debugging/testing)
    save_disrupted_patches: NULL

    # Whether to visualize the disrupted patches
    visualize_disrupted: false

# -----------------------------------------------------------------------------
# (H) Evaluation Metrics
# -----------------------------------------------------------------------------
evaluation:
  compute_metrics: false

# -----------------------------------------------------------------------------
# (I) Profiling Feature Flags
# -----------------------------------------------------------------------------
profiling:
  features:
    # Compute per-channel Laplacian variance (expensive); disable to speed up profiling.
    compute_laplacian: false

    # Compute per-channel coefficient of variation; disable to save time.
    compute_cov: false

    # Dtype for per-channel intensity calculations; float32 reduces memory/compute.
    channel_dtype: float32

    # GPU acceleration for bincount operations (requires CuPy and CUDA-compatible GPU)
    # Provides 10-20x speedup for large samples (>1M cells)
    # Automatically falls back to CPU if GPU unavailable
    use_gpu: true

    # GPU batch size (number of channels to process at once on GPU)
    # Set to 0 for automatic detection based on available VRAM
    # Larger batches are faster but require more GPU memory
    gpu_batch_size: 0
report:
  generate_report: true
  report_format: html
