"use strict";(self.webpackChunkaegle_docs=self.webpackChunkaegle_docs||[]).push([[232],{7320:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>l,contentTitle:()=>c,default:()=>p,frontMatter:()=>r,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"Main/Preprocess","title":"Preprocess","description":"This document describes the preprocessing pipeline for CODEX images in Aegle. The preprocessing consists of two main stages: Full Image Preprocessing and Patched Image Preprocessing, as implemented in aegle/pipeline.py under the run_pipeline function.","source":"@site/docs/Main/Preprocess.md","sourceDirName":"Main","slug":"/Main/Preprocess","permalink":"/aegle/docs/Main/Preprocess","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Main/Preprocess.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Outputs","permalink":"/aegle/docs/Main/Outputs"},"next":{"title":"Downstream Analysis","permalink":"/aegle/docs/category/downstream-analysis"}}');var a=n(4848),t=n(8453);const r={sidebar_position:2},c="Preprocess",l={},o=[{value:"A. Full Image Preprocessing",id:"a-full-image-preprocessing",level:2},{value:"Step A1: Initialize <code>CodexImage</code>",id:"step-a1-initialize-codeximage",level:3},{value:"Step A2: Extract Target Channels",id:"step-a2-extract-target-channels",level:3},{value:"Optional: Visualize Whole Sample",id:"optional-visualize-whole-sample",level:3},{value:"B. Patched Image Preprocessing",id:"b-patched-image-preprocessing",level:2},{value:"Step B1: Extend Image",id:"step-b1-extend-image",level:3},{value:"Step B2: Initialize <code>CodexPatches</code> and Save Patches",id:"step-b2-initialize-codexpatches-and-save-patches",level:3},{value:"Optional: Add Disruptions",id:"optional-add-disruptions",level:3},{value:"Optional: Visualize Patches",id:"optional-visualize-patches",level:3}];function d(e){const s={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(s.header,{children:(0,a.jsx)(s.h1,{id:"preprocess",children:"Preprocess"})}),"\n",(0,a.jsxs)(s.p,{children:["This document describes the preprocessing pipeline for CODEX images in Aegle. The preprocessing consists of two main stages: ",(0,a.jsx)(s.strong,{children:"Full Image Preprocessing"})," and ",(0,a.jsx)(s.strong,{children:"Patched Image Preprocessing"}),", as implemented in ",(0,a.jsx)(s.code,{children:"aegle/pipeline.py"})," under the ",(0,a.jsx)(s.code,{children:"run_pipeline"})," function."]}),"\n",(0,a.jsx)(s.p,{children:"Key outputs include:"}),"\n",(0,a.jsx)(s.h2,{id:"a-full-image-preprocessing",children:"A. Full Image Preprocessing"}),"\n",(0,a.jsx)(s.p,{children:"This stage prepares the full CODEX image for downstream patch-level processing."}),"\n",(0,a.jsxs)(s.h3,{id:"step-a1-initialize-codeximage",children:["Step A1: Initialize ",(0,a.jsx)(s.code,{children:"CodexImage"})]}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsxs)(s.li,{children:["Constructs a ",(0,a.jsx)(s.code,{children:"CodexImage"})," object using configuration parameters and command-line arguments."]}),"\n",(0,a.jsx)(s.li,{children:"Loads the image and its corresponding antibody metadata."}),"\n",(0,a.jsxs)(s.li,{children:["If enabled in the configuration (",(0,a.jsx)(s.code,{children:"data.generate_channel_stats: true"}),"), calculates statistics across channels."]}),"\n"]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"codex_image = CodexImage(config, args)\ncodex_image.calculate_channel_statistics()\n"})}),"\n",(0,a.jsx)(s.h3,{id:"step-a2-extract-target-channels",children:"Step A2: Extract Target Channels"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsx)(s.li,{children:"Uses configuration to extract biologically relevant channels (e.g. membrane or nucleus markers)."}),"\n"]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"codex_image.extract_target_channels()\n"})}),"\n",(0,a.jsx)(s.h3,{id:"optional-visualize-whole-sample",children:"Optional: Visualize Whole Sample"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsxs)(s.li,{children:["Saves RGB visualizations of extracted channels to the output directory if ",(0,a.jsx)(s.code,{children:"visualization.visualize_whole_sample"})," is set to ",(0,a.jsx)(s.code,{children:"true"}),"."]}),"\n"]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"save_image_rgb(codex_image.extended_extracted_channel_image, ...)\nsave_image_rgb(codex_image.extracted_channel_image, ...)\n"})}),"\n",(0,a.jsx)(s.hr,{}),"\n",(0,a.jsx)(s.h2,{id:"b-patched-image-preprocessing",children:"B. Patched Image Preprocessing"}),"\n",(0,a.jsx)(s.p,{children:"This stage slices the image into overlapping patches and optionally applies perturbations for robustness testing."}),"\n",(0,a.jsx)(s.h3,{id:"step-b1-extend-image",children:"Step B1: Extend Image"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsx)(s.li,{children:"Pads the original image to ensure that all patches are fully contained within the image bounds."}),"\n"]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"codex_image.extend_image()\n"})}),"\n",(0,a.jsxs)(s.h3,{id:"step-b2-initialize-codexpatches-and-save-patches",children:["Step B2: Initialize ",(0,a.jsx)(s.code,{children:"CodexPatches"})," and Save Patches"]}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsxs)(s.li,{children:["Initializes a ",(0,a.jsx)(s.code,{children:"CodexPatches"})," object using the extended ",(0,a.jsx)(s.code,{children:"CodexImage"}),", then generates and saves patches."]}),"\n",(0,a.jsx)(s.li,{children:"Patch metadata is also saved."}),"\n"]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"codex_patches = CodexPatches(codex_image, config, args)\ncodex_patches.save_patches(...)\ncodex_patches.save_metadata()\n"})}),"\n",(0,a.jsx)(s.h3,{id:"optional-add-disruptions",children:"Optional: Add Disruptions"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsx)(s.li,{children:"If configured, adds synthetic noise or perturbations to patches for testing robustness."}),"\n",(0,a.jsxs)(s.li,{children:["Disruption parameters include ",(0,a.jsx)(s.code,{children:"type"})," and ",(0,a.jsx)(s.code,{children:"level"}),", and the disrupted patches can be optionally saved and visualized."]}),"\n"]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:'disruption_type = disruption_config.get("type")\ndisruption_level = disruption_config.get("level", 1)\ncodex_patches.add_disruptions(disruption_type, disruption_level)\ncodex_patches.save_disrupted_patches()\n'})}),"\n",(0,a.jsx)(s.h3,{id:"optional-visualize-patches",children:"Optional: Visualize Patches"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsxs)(s.li,{children:["RGB visualizations of either the original or disrupted patches are saved if ",(0,a.jsx)(s.code,{children:"visualization.visualize_patches"})," is set to ",(0,a.jsx)(s.code,{children:"true"}),"."]}),"\n"]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"save_patches_rgb(codex_patches.extracted_channel_patches, ...)\n"})}),"\n",(0,a.jsx)(s.hr,{}),"\n",(0,a.jsx)(s.p,{children:"This preprocessing module prepares both the full and patched images for subsequent segmentation and analysis steps. All outputs are saved in a structured format for downstream reproducibility."})]})}function p(e={}){const{wrapper:s}={...(0,t.R)(),...e.components};return s?(0,a.jsx)(s,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,s,n)=>{n.d(s,{R:()=>r,x:()=>c});var i=n(6540);const a={},t=i.createContext(a);function r(e){const s=i.useContext(t);return i.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function c(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(t.Provider,{value:s},e.children)}}}]);