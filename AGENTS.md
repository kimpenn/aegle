# Repository Guidelines

## Project Structure & Module Organization
The Git repo root is `/workspaces/codex-analysis/0-phenocycler-penntmc-pipeline`, so assume all relative paths start there unless otherwise noted. Core Python modules that drive preprocessing, segmentation, and reporting live in `aegle/`, while downstream analytics sit in `aegle_analysis/`. Command-line entry points (e.g., `src/main.py`, `src/run_analysis.py`, `src/extract_tissue_regions.py`) wrap the package functions so agents can wire configs without editing the package. Shell harnesses such as `launcher/run_main_ft.sh`, `launcher/run_preprocess_ft.sh`, and the helper scripts under `scripts/` orchestrate typical PennTMC scenarios. Images, masks, and experiment outputs are staged in `data/`, `out/`, and `logs/`, and reusable YAML configurations reside in `exps/configs/` with templates under `exps/templates/`. Unit and integration tests are grouped under `tests/`, mirroring the pipeline stages (`tests/preprocess`, `tests/main`, `tests/analysis`, plus shared helpers in `tests/utils`). Keep notebooks and scratch analyses inside `notebooks/` or `debug/` to avoid mixing exploratory code with shipping modules.

## Build, Test, and Development Commands
- `python -m pip install -e .` — install the `aegle` package in editable mode so module imports (e.g., `from aegle.pipeline import run_pipeline`) resolve consistently.
- `python src/main.py --config_file exps/templates/main_template.yaml --data_dir data/D18_Scan1 --out_dir out/dev_run` — execute the full pipeline with a template configuration; override `--resume_stage cell_profiling` to restart downstream steps only.
- `python src/run_analysis.py --config_file exps/templates/analysis_template.yaml --data_dir out/main/main_ft_hb --output_dir out/analysis/dev` — run the post-segmentation analytics stack using the outputs from a prior main run.
- `bash launcher/run_main_ft.sh exps/configs/main/main_ft_da/D18_0/config.yaml` — invoke the maintained FT workflow wrapper; similar scripts exist for `launcher/run_preprocess_*` and cohort-specific entry points.

## Coding Style & Naming Conventions
Python 3 code follows PEP 8: four-space indentation, `snake_case` functions, `UpperCamelCase` classes, and `UPPER_SNAKE` constants. Modules already mix type hints (`Tuple`, `Dict`) with docstrings—extend that pattern when touching files such as `aegle/repair_masks.py` or `tests/test_segment.py`. Prefer structured `logging` (see `src/main.py:setup_logging`) over ad-hoc prints so the shell harnesses can capture run metadata. Keep scripts and config directories lowercase with underscores (`run_analysis_ft.sh`, `exps/configs/preprocess/...`). Plotting helpers should describe channels or antibodies explicitly in the legend/title to match existing figures in `aegle/visualization_segmentation.py`.

## Testing Guidelines
Use the in-repo unittest suite as the safety net. Run all checks with `python -m unittest discover -s tests`, or target a module—`python -m unittest tests.test_cell_profiling_features` mirrors the synthetic factory workflow documented in `tests/README.md`. When adding scenario-specific scripts under `tests/main`, include a brief comment that states the upstream `.sh` file it wraps (e.g., `launcher/run_main_test.sh`). Regenerate previews with the helper snippet in `tests/README.md` whenever synthetic test fixtures change so reviewers can verify the rendered `debug_synthetic_previews/` assets. If a feature depends on external GPU inference, gate the test with environment checks and fall back to deterministic NumPy fixtures.

## Commit & Pull Request Guidelines
Follow the short imperative commit style already in `git log` (e.g., “Added nucleus_overview.csv generation”, “Cleaned up cell_overview.csv”). Bundle logical units: configuration changes, code, and docs should land together so rerunning `run_main_ft.sh` with the referenced YAML reproduces results. Every pull request description should list: (1) the primary command used for validation, (2) the relevant configuration path (e.g., `exps/configs/main/main_ft_da/D11_0/config.yaml`), and (3) any produced artifacts or screenshots for visualization tweaks. Link tracking issues and note any large sample data that cannot be committed; stage minimal CSV/NPZ stubs in `tests/data/` instead. Launcher scripts are located in the `launcher/` directory.

## Data & Configuration Tips
Treat `exps/templates/*.yaml` as the canonical starting point, copying them into `exps/configs/<stage>/<cohort>/<scan>/config.yaml` when onboarding a new sample. Keep raw PhenoCycler deliveries in `data/` and ensure derived artifacts (`out/`, `debug/`, `logs/`) stay git-ignored—share reproducibility details via config diffs rather than uploading binary tiles. Scripts assume relative paths inside the repo root; when building new orchestrators, echo both `--data_dir` and `--out_dir` so automated agents can rediscover the run context. Launcher scripts (e.g., `launcher/run_main_ft.sh`) provide cohort-specific wrappers. Verify that secrets (API tokens for optional LLM-assisted annotation in `src/run_analysis.py`) are provided through environment variables or `.env` files listed in `.gitignore`, never in tracked configs.

## Runtime Defaults
Most production runs use `patching.split_mode: full_image`; prefer optimizations that keep the single-patch path efficient and avoid per-patch chatter that adds little value in that mode.
